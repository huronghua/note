1.mysql分页有什么优化？
普通的limit写法数据量越大查询效率越慢，因为需要逐行扫描出M+N条记录再取出N条，总结经验就是尽可能用索引去查询出需要查询的那些记录成临时表再进行关联查询。
不显示总页数，只显示上一页下一页，通过查询该页的数据时多查一条记录但只取该页的数据来判断是否有下一页，没有就置灰。
获取总数优化：根据业务维度（时间维度或者用户维度）分库分表，否则尽量不要去获取记录的总条数。
获取数据的优化：先查询翻页中需要的N条数据的主键id，然后根据主键id去查询你所需要的N条数据，此过程中查询N条数据的主键ID在索引中完成。
				select * from order_info,(select order_id from order_info where channels_id=35 order by order_id desc limit 1320000,20) order_info_tmp where order_info.order_id = order_info_tmp.order_id
2.乐观锁悲观锁？
悲观锁：就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁。
		 (1)对任何记录进行修改前，先尝试为该记录加排它锁，加锁失败说明有其余事务正在进行修改需要等到该事务提交释放锁，成功就可以进行修改，修改成功后释放锁。
		 (2)关闭自动提交属性  setautocommit = 0; 通过select ... from table for update加锁   行级索是基于索引的，如果sql语句用不到索引就会进行整表锁定需要注意。
		 (3)优点是数据安全一致性提供了保证，但是加锁使得效率很低而且还有可能产生死锁。
乐观锁：很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。
		  (1)使用数据版本，给表添加一个version字段，每次更新操作都会对版本号+1，在更新操作时比较之前一次读操作时的version是否一致，一致就说明这期间没有别的事务进行过更新。
		  (2)使用时间戳，原理同version版本标识符。
		  (3)优点是效率很高。
		  乐观锁就在更新的那一瞬间锁了下，悲观锁从准备开始更新操作时就加锁，锁的时间比乐观锁长，所有的update语句都会加锁。

3、组合索引，最左原则
索引就好比查字典，通过不断缩小范围最终确定需要查找的值
b+树叶子节点存储真实数据项，非叶子节点只存储指引搜索方向的数据项
b+树性质：
1.我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高

2.当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时

建索引的原则
1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配
2.=和in可以乱序
3.尽量选择区分度高的列作为索引，就是重复出现的概率越小，区分度越高
4.索引列不能参与计算比如from_unixtime(create_time)对create_time进行时间格式化了
5.尽量的扩展索引，不要新建索引即尽量建立联合索引

优化方法：
主要看row属性和type属性
0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE
1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高，设置索引但不一定总是区分度低的就不能建索引
2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）
3.order by limit 形式的sql语句让排序的表优先查
4.了解业务方使用场景
5.加索引时参照建索引的几大原则
6.观察结果，不符合预期继续从0分析
		  
4、mysql 的表锁、行锁
表锁：锁住的是整张表，并发能力差
行锁：锁住的是有限行的记录，其他行仍可以访问，并发能力好（select是不会加锁的（除了serializable级别），update、delete都会加锁）
	  在没有索引的行上加锁会导致全表加锁，实际过程中发现被锁的行不满足条件时mysql会及时解锁
隔离级别：
未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据
提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)
可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读（事务B修改id=1的数据提交之后，事务A同样的查询，后一次和前一次的结果不一样，这就是不可重读，不可重复读重点在于update和delete，而幻读的重点在于insert）
串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞
如果使用锁机制来实现这两种隔离级别，在可重复读中，该sql第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据，就可以实现可重复读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要Serializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。
如果使用的是没有索引的字段，比如update class_teacher set teacher_id=7 where class_name='初三八班（即使没有匹配到任何数据）',那么会给全表加入gap锁。同时，它不能像上文中行锁一样经过MySQL Server过滤自动解除不满足条件的锁
行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别在写数据时的幻读问题。

5、mysql 性能优化
1.sql查询优化、索引优化
2.表结构优化、字段类型优化  分库分表  水平拆分  垂直拆分	
3.使用各种缓存减小DB压力

6、mysql的索引分类：B+，hash；什么情况用什么索引
1. hash索引查找数据基本上能一次定位数据，当然有大量碰撞的话性能也会下降。而btree索引就得在节点上挨着查找了，很明显在数据精确查找方面hash索引的效率是要高于btree的。
2. 那么不精确查找呢，也很明显，因为hash算法是基于等值计算的，所以对于“like”等范围查找hash索引无效，不支持，也无法利用索引完成排序。
3. 对于btree支持的联合索引的最优前缀，hash也是无法支持的，联合索引中的字段要么全用要么全不用。
